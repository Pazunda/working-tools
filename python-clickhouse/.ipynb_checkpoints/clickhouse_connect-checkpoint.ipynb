{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandahouse\n",
      "  Downloading pandahouse-0.2.7.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandahouse) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandahouse) (2.28.1)\n",
      "Requirement already satisfied: toolz in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandahouse) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandas->pandahouse) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandas->pandahouse) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from pandas->pandahouse) (2022.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from requests->pandahouse) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from requests->pandahouse) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from requests->pandahouse) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from requests->pandahouse) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pazun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->pandahouse) (1.16.0)\n",
      "Building wheels for collected packages: pandahouse\n",
      "  Building wheel for pandahouse (setup.py): started\n",
      "  Building wheel for pandahouse (setup.py): finished with status 'done'\n",
      "  Created wheel for pandahouse: filename=pandahouse-0.2.7-py2.py3-none-any.whl size=5912 sha256=257e08a77613a14e607ad62356f7da5e2fd13e7de1eadf1834ddaadc230ed0ec\n",
      "  Stored in directory: c:\\users\\pazun\\appdata\\local\\pip\\cache\\wheels\\2b\\75\\4a\\22824efa98a925fce4a1f2c18e85b55eb75179dfb9e9d59f45\n",
      "Successfully built pandahouse\n",
      "Installing collected packages: pandahouse\n",
      "Successfully installed pandahouse-0.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandahouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортируем нужные либы\n",
    "import pandahouse as ph\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#объявляем параметры подключения\n",
    "connection = dict(database='test',\n",
    "                  host='https://clickhouse.lab.karpov.courses',\n",
    "                  user='student-rw',\n",
    "                  password='656e2b0c9c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstallationDate</th>\n",
       "      <th>InstallCost</th>\n",
       "      <th>Platform</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>android</td>\n",
       "      <td>7950068545577019282</td>\n",
       "      <td>Source_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>49</td>\n",
       "      <td>android</td>\n",
       "      <td>17173992779193729517</td>\n",
       "      <td>Source_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>56</td>\n",
       "      <td>android</td>\n",
       "      <td>9528182466778893591</td>\n",
       "      <td>Source_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>39</td>\n",
       "      <td>android</td>\n",
       "      <td>2212531864415574595</td>\n",
       "      <td>Source_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>0</td>\n",
       "      <td>android</td>\n",
       "      <td>6959033924999748551</td>\n",
       "      <td>Source_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>334</td>\n",
       "      <td>android</td>\n",
       "      <td>5435327797863630841</td>\n",
       "      <td>Source_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>19</td>\n",
       "      <td>iOS</td>\n",
       "      <td>16012086443778979967</td>\n",
       "      <td>Source_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>0</td>\n",
       "      <td>iOS</td>\n",
       "      <td>1637578224854940304</td>\n",
       "      <td>Source_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>171</td>\n",
       "      <td>android</td>\n",
       "      <td>9176486286906828772</td>\n",
       "      <td>Source_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>android</td>\n",
       "      <td>9240230502613874345</td>\n",
       "      <td>Source_27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    InstallationDate  InstallCost Platform              DeviceID     Source\n",
       "0         2019-03-02            0  android   7950068545577019282  Source_27\n",
       "1         2019-03-17           49  android  17173992779193729517  Source_14\n",
       "2         2019-04-07           56  android   9528182466778893591  Source_14\n",
       "3         2019-06-25           39  android   2212531864415574595   Source_9\n",
       "4         2019-04-13            0  android   6959033924999748551  Source_27\n",
       "..               ...          ...      ...                   ...        ...\n",
       "995       2019-01-09          334  android   5435327797863630841  Source_14\n",
       "996       2019-03-05           19      iOS  16012086443778979967   Source_9\n",
       "997       2019-06-12            0      iOS   1637578224854940304  Source_27\n",
       "998       2019-07-01          171  android   9176486286906828772   Source_9\n",
       "999       2019-09-20            0  android   9240230502613874345  Source_27\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пишем запрос, и получаем данные из clickhouse в pandas dataframe\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM test.installs\n",
    "limit 1000\n",
    "\"\"\"\n",
    "df = ph.read_clickhouse(query, connection=connection)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выгружаем данные из pandas в excel\n",
    "df.to_excel(\"./ch_data.xlsx\", sheet_name='Data', index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-13 22:54:53.510Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/policy/medium-terms-of-serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-13 22:57:17.248Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/policy/medium-privacy-polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-04 23:40:43.364Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@Medium/personalize-your-me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-24 18:21:13.427Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/holiday-poems/xmas-morning-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-22 21:37:48.207Z</td>\n",
       "      <td>blog.medium.com</td>\n",
       "      <td>https://blog.medium.com/taking-a-side-on-net-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92186</th>\n",
       "      <td>2017-05-23 17:15:09.193Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@KyleAndrews1994/its-time-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92187</th>\n",
       "      <td>2017-01-31 09:59:12.316Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/silent-protagonist/next-wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92188</th>\n",
       "      <td>2017-02-16 14:15:20.116Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@utapartment26/there-used-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92189</th>\n",
       "      <td>2017-06-27 10:16:21.668Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/silent-protagonist/the-snes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92190</th>\n",
       "      <td>2017-06-12 06:49:29.954Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/silent-protagonist/assassin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92191 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      published           domain  \\\n",
       "0      2012-08-13 22:54:53.510Z       medium.com   \n",
       "1      2012-08-13 22:57:17.248Z       medium.com   \n",
       "2      2016-11-04 23:40:43.364Z       medium.com   \n",
       "3      2016-12-24 18:21:13.427Z       medium.com   \n",
       "4      2015-09-22 21:37:48.207Z  blog.medium.com   \n",
       "...                         ...              ...   \n",
       "92186  2017-05-23 17:15:09.193Z       medium.com   \n",
       "92187  2017-01-31 09:59:12.316Z       medium.com   \n",
       "92188  2017-02-16 14:15:20.116Z       medium.com   \n",
       "92189  2017-06-27 10:16:21.668Z       medium.com   \n",
       "92190  2017-06-12 06:49:29.954Z       medium.com   \n",
       "\n",
       "                                                     url  \n",
       "0      https://medium.com/policy/medium-terms-of-serv...  \n",
       "1      https://medium.com/policy/medium-privacy-polic...  \n",
       "2      https://medium.com/@Medium/personalize-your-me...  \n",
       "3      https://medium.com/holiday-poems/xmas-morning-...  \n",
       "4      https://blog.medium.com/taking-a-side-on-net-n...  \n",
       "...                                                  ...  \n",
       "92186  https://medium.com/@KyleAndrews1994/its-time-t...  \n",
       "92187  https://medium.com/silent-protagonist/next-wee...  \n",
       "92188  https://medium.com/@utapartment26/there-used-t...  \n",
       "92189  https://medium.com/silent-protagonist/the-snes...  \n",
       "92190  https://medium.com/silent-protagonist/assassin...  \n",
       "\n",
       "[92191 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#читаем данные из csv в pandas\n",
    "df_in = pd.read_csv(\"./medium.csv\", sep='\\t')\n",
    "df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClickhouseException",
     "evalue": "b'Code: 57. DB::Exception: Table test.a_pos_import_test already exists. (TABLE_ALREADY_EXISTS) (version 21.12.2.17 (official build))\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandahouse\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(query, connection, data, external, stream)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRequestException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://clickhouse.lab.karpov.courses/?query=CREATE+TABLE+test.a_pos_import_test+%28%0A++++published+String%2C%0A++++domain+String%2C%0A++++url+String%0A%29%0AENGINE+%3D+Log+FORMAT+TSVWithNamesAndTypes&user=student-rw&password=656e2b0c9c",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mClickhouseException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16636\\2036923896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mENGINE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \"\"\"\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf_create\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_clickhouse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_create\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mdf_create\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandahouse\\core.py\u001b[0m in \u001b[0;36mread_clickhouse\u001b[1;34m(query, tables, index, connection, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m     55\u001b[0m     \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexternal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     lines = execute(query, external=external, stream=True,\n\u001b[0m\u001b[0;32m     57\u001b[0m                     connection=connection)\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandahouse\\http.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(query, connection, data, external, stream)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRequestException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mClickhouseException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mClickhouseException\u001b[0m: b'Code: 57. DB::Exception: Table test.a_pos_import_test already exists. (TABLE_ALREADY_EXISTS) (version 21.12.2.17 (official build))\\n'"
     ]
    }
   ],
   "source": [
    "#пишем запрос, и получаем данные из clickhouse в pandas dataframe\n",
    "query_create = \"\"\"\n",
    "CREATE TABLE test.a_pos_import_test (\n",
    "    published String,\n",
    "    domain String,\n",
    "    url String\n",
    ")\n",
    "ENGINE = Log\n",
    "\"\"\"\n",
    "df_create = ph.read_clickhouse(query_create, connection=connection)\n",
    "df_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92191"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#записываем данные из pandas в clickhouse\n",
    "ph.to_clickhouse(df_in, 'beslan_import_test', index=False, connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-09 13:12:26.911Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@raphael.carvalheira/como-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-09 13:15:45.000Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@raphael.carvalheira/ensaio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-04 14:01:03.415Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/starts-with-a-bang/why-does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-22 15:05:21.254Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/laguna-serpiente/apuntes-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 15:01:11.442Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/laguna-serpiente/brujer%C3%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635067</th>\n",
       "      <td>2017-02-20 11:08:13.000Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://www.cold-steel.org/2017/ss-gb-review/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635068</th>\n",
       "      <td>2017-05-08 21:08:59.838Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/@brupaese/como-podemos-ajud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635069</th>\n",
       "      <td>2017-05-08 12:14:22.198Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/copyright-untangled/teacher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635070</th>\n",
       "      <td>2017-03-29 13:23:15.183Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/copyright-untangled/launche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635071</th>\n",
       "      <td>2017-03-21 15:39:01.002Z</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>https://medium.com/read-write-participate/make...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        published      domain  \\\n",
       "0        2016-11-09 13:12:26.911Z  medium.com   \n",
       "1        2016-11-09 13:15:45.000Z  medium.com   \n",
       "2        2016-11-04 14:01:03.415Z  medium.com   \n",
       "3        2015-09-22 15:05:21.254Z  medium.com   \n",
       "4        2016-01-11 15:01:11.442Z  medium.com   \n",
       "...                           ...         ...   \n",
       "2635067  2017-02-20 11:08:13.000Z  medium.com   \n",
       "2635068  2017-05-08 21:08:59.838Z  medium.com   \n",
       "2635069  2017-05-08 12:14:22.198Z  medium.com   \n",
       "2635070  2017-03-29 13:23:15.183Z  medium.com   \n",
       "2635071  2017-03-21 15:39:01.002Z  medium.com   \n",
       "\n",
       "                                                       url  \n",
       "0        https://medium.com/@raphael.carvalheira/como-s...  \n",
       "1        https://medium.com/@raphael.carvalheira/ensaio...  \n",
       "2        https://medium.com/starts-with-a-bang/why-does...  \n",
       "3        https://medium.com/laguna-serpiente/apuntes-pa...  \n",
       "4        https://medium.com/laguna-serpiente/brujer%C3%...  \n",
       "...                                                    ...  \n",
       "2635067      https://www.cold-steel.org/2017/ss-gb-review/  \n",
       "2635068  https://medium.com/@brupaese/como-podemos-ajud...  \n",
       "2635069  https://medium.com/copyright-untangled/teacher...  \n",
       "2635070  https://medium.com/copyright-untangled/launche...  \n",
       "2635071  https://medium.com/read-write-participate/make...  \n",
       "\n",
       "[2635072 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверяем, что записалось\n",
    "query_test = \"\"\"\n",
    "SELECT *\n",
    "FROM test.beslan_import_test\n",
    "\"\"\"\n",
    "df_new = ph.read_clickhouse(query_test, connection=connection)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
